# crawler_config.yaml - 爬虫配置文件

# 基础配置
basic:
  data_dir: "data"
  log_level: "INFO"
  max_retry: 3
  request_delay: [1, 3] # 请求延迟范围（秒）

# 爬虫配置
crawler:
  target_url: "https://www.zhihu.com/hot"
  max_items: 50
  extract_details_for_top: 20 # 只对前N条提取详细信息
  user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

  # Chrome浏览器选项
  chrome_options:
    - "--disable-blink-features=AutomationControlled"
    - "--disable-gpu"
    - "--disable-software-rasterizer"
    - "--no-sandbox"
    - "--disable-dev-shm-usage"

# 定时任务配置
scheduler:
  timezone: "Asia/Shanghai"

  # 爬取任务
  crawl_jobs:
    basic_crawl:
      cron: "0 */2 * * *" # 每2小时
      extract_details: false
      enabled: true

    detailed_crawl:
      cron: "30 */6 * * *" # 每6小时的30分
      extract_details: true
      enabled: true

  # 分析任务
  analysis_jobs:
    daily_report:
      cron: "0 8 * * *" # 每天8点
      days: 7
      enabled: true

    weekly_report:
      cron: "0 9 * * 1" # 每周一9点
      days: 30
      enabled: true

# 数据分析配置
analysis:
  chart_style: "seaborn-v0_8"
  figure_size: [15, 10]
  dpi: 300

  # 要分析的字段
  analyze_fields:
    - "rank"
    - "answer_count"
    - "follower_count"
    - "view_count"
    - "question_tags"

  # 报告配置
  report:
    include_charts: true
    max_tags_display: 10
    max_history_days: 30

# 去重配置
deduplication:
  enabled: true
  hash_algorithm: "md5"
  storage_file: "question_hashes.json"

# 存储配置
storage:
  formats: ["json"] # 支持: json, csv, xlsx
  compression: false
  backup_enabled: true
  max_backup_files: 10

# 通知配置（可扩展）
notifications:
  email:
    enabled: false
    smtp_server: ""
    smtp_port: 587
    username: ""
    password: ""
    recipients: []

  webhook:
    enabled: false
    url: ""
